# -*- coding: utf-8 -*-
"""gender-age-ethnicity-classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ar4q7hH6D3N_6y79WrIvdrQzOiYtuef_

# Multi task for gender, age and ethnicity classification

Author : Utpalraj Kemprai

## Importing libraries
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
import os
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt

"""## Downloading the Fairface dataset"""

# download dataset and unzip
!kaggle datasets download mehmoodsheikh/fairface-dataset
!unzip fairface-dataset.zip -d fairface

"""## View the dataset"""

label_train_data = pd.read_csv('/content/fairface/FairFace/fairface_label_train.csv')
label_train_data.head()

label_train_data['age'].unique()

# plot the bar graph for age
label_train_data['age'].value_counts().plot(kind='bar')

label_train_data['gender'].unique()

# plot the bar graph for gender
label_train_data['gender'].value_counts().plot(kind='bar')

label_train_data['race'].unique()

# plot the bar graph for race
label_train_data['race'].value_counts().plot(kind='bar')

label_train_data.isna().mean()

"""## Process the data for training and validation"""

class FairFaceMultiTaskDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

        # Define mappings for age and ethnicity
        self.age_mapping = {'0-2': 0, '3-9': 1, '10-19': 2, '20-29': 3, '30-39': 4, '40-49': 5, '50-59': 6, '60-69': 7, 'more than 70': 8}
        self.ethnicity_mapping = {'White': 0, 'Black': 1, 'Latino_Hispanic': 2, 'East Asian': 3, 'Southeast Asian': 4, 'Indian': 5, 'Middle Eastern': 6}

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])
        image = Image.open(img_path).convert("RGB")

        # Extract labels for gender, age, and ethnicity
        gender_label = 0 if self.annotations.iloc[idx, 2] == 'Male' else 1
        age_label = self.age_mapping[self.annotations.iloc[idx, 1]]
        ethnicity_label = self.ethnicity_mapping[self.annotations.iloc[idx, 3]]

        if self.transform:
            image = self.transform(image)

        return image, (gender_label, age_label, ethnicity_label)

transform = transforms.Compose([
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load dataset
train_dataset = FairFaceMultiTaskDataset(csv_file='fairface/FairFace/fairface_label_train.csv', root_dir='fairface/FairFace', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_dataset =  FairFaceMultiTaskDataset(csv_file='fairface/FairFace/fairface_label_val.csv', root_dir='fairface/FairFace', transform=transform)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

"""## Define the CNN model"""

class CNN(nn.Module):
    def __init__(self, input_size, num_age_classes, num_ethnicity_classes ):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3,padding=0)
        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=6,padding=0)
        self.conv3 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=6,padding=0)
        self.fc1 = nn.Linear(8*4*4, 200)
        self.fc2 = nn.Linear(200, 10)

        # Task-specific output layers
        self.gender_fc = nn.Linear(10, 2)              # Output for gender classification (2 classes)
        self.age_fc = nn.Linear(10, num_age_classes)   # Output for age classification
        self.ethnicity_fc = nn.Linear(10, num_ethnicity_classes)  # Output for ethnicity classification

    def forward(self, x, verbose=False):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, kernel_size=2)
        x = self.conv3(x)
        x = F.relu(x)
        x = F.max_pool2d(x, kernel_size=2)
        x = x.view(-1, 8*4*4)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)

        # Task-specific outputs
        gender_output = F.log_softmax(self.gender_fc(x), dim=1)
        age_output = F.log_softmax(self.age_fc(x), dim=1)
        ethnicity_output = F.log_softmax(self.ethnicity_fc(x), dim=1)

        return gender_output, age_output, ethnicity_output

# Define number of classes for each task
num_age_classes = 9         # Example: 9 age ranges (adjust as per your data)
num_ethnicity_classes = 7   # Example: 7 ethnicity classes

# Initialize model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

"""### Initialize the model"""

# Instantiate and check the number of trainable parameters
model = CNN(28*28,num_age_classes,num_ethnicity_classes).to(device)
print(f"Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}")

print(model)

"""### Loss functions and optimizer"""

# Loss functions for each output
gender_criterion = nn.CrossEntropyLoss()
age_criterion = nn.CrossEntropyLoss()
ethnicity_criterion = nn.CrossEntropyLoss()

# Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.002)

"""### Function for model evaluation"""

def evaluate(model, val_loader):
    model.eval()
    gender_correct, age_correct, ethnicity_correct = 0, 0, 0
    total = 0

    with torch.no_grad():
        for images, (gender_labels, age_labels, ethnicity_labels) in val_loader:
            images = images.to(device)
            gender_labels = gender_labels.to(device)
            age_labels = age_labels.to(device)
            ethnicity_labels = ethnicity_labels.to(device)

            gender_output, age_output, ethnicity_output = model(images)

            # Calculate accuracy for each task
            gender_correct += (gender_output.argmax(1) == gender_labels).sum().item()
            age_correct += (age_output.argmax(1) == age_labels).sum().item()
            ethnicity_correct += (ethnicity_output.argmax(1) == ethnicity_labels).sum().item()
            total += gender_labels.size(0)

    print(f"Gender Accuracy: {100 * gender_correct / total:.2f}%")
    print(f"Age Accuracy: {100 * age_correct / total:.2f}%")
    print(f"Ethnicity Accuracy: {100 * ethnicity_correct / total:.2f}%")

len(train_dataset)

"""## Training the model and evaluation"""

num_epochs = 10
losses = []
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    batch_idx = 1
    for images, (gender_labels, age_labels, ethnicity_labels) in train_loader:
        images = images.to(device)
        gender_labels = gender_labels.to(device)
        age_labels = age_labels.to(device)
        ethnicity_labels = ethnicity_labels.to(device)

        optimizer.zero_grad()

        # Forward pass
        gender_output, age_output, ethnicity_output = model(images)

        # Compute individual losses and combine them
        gender_loss = gender_criterion(gender_output, gender_labels)
        age_loss = age_criterion(age_output, age_labels)
        ethnicity_loss = ethnicity_criterion(ethnicity_output, ethnicity_labels)

        total_loss = gender_loss + age_loss + ethnicity_loss
        total_loss.backward()
        optimizer.step()

        if batch_idx % 100 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch+1, batch_idx * len(gender_labels), len(train_dataset),
                100. * batch_idx / len(train_loader), total_loss.item()))
        batch_idx += 1

        running_loss += total_loss.item()
    losses.append(total_loss.item())

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")
    evaluate(model, val_loader)

# # plot the losses vs the number of epochs
# epochs = list(range(1, len(losses)+1))
# plt.plot(epochs,losses)
# plt.xlabel("Epochs")
# plt.ylabel("Training loss")
# plt.title("Training loss vs Epochs")
# plt.show()

# Run evaluation
evaluate(model, val_loader)

"""## Saving the model"""

# Save the model state dictionary
model_path = 'multi_task_inceptionv3.pth'
torch.save(model.state_dict(), model_path)
print(f"Model saved to {model_path}")

"""## visualizing the output for some sample images"""

def predict_proba(model, image_path, transform, device):
    """
    Predicts the probability distribution for gender, age, and ethnicity.

    Args:
        model: The trained multi-task model.
        image_path: Path to the input image.
        transform: Image transformations.
        device: Device to run the model on.

    Returns:
        A dictionary containing the image and probability distributions for gender, age, and ethnicity.
    """

    model.eval()
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        gender_output, age_output, ethnicity_output = model(image)

    # Convert outputs to probability distributions
    gender_proba = torch.softmax(gender_output, dim=1).cpu().numpy()[0]
    age_proba = torch.softmax(age_output, dim=1).cpu().numpy()[0]
    ethnicity_proba = torch.softmax(ethnicity_output, dim=1).cpu().numpy()[0]

    return {
        'image': image_path,
        'gender_proba': gender_proba,
        'age_proba': age_proba,
        'ethnicity_proba': ethnicity_proba
    }

def plot_results(prediction_result):
    """Plots the image, gender, age, and ethnicity probabilities in a single row."""

    fig, axes = plt.subplots(1, 4, figsize=(20, 5))

    # Plot the image
    image = Image.open(prediction_result['image']).convert("RGB")
    axes[0].imshow(image)
    axes[0].set_title("Image")
    axes[0].axis('off')

    # Plot gender probability
    labels = ['Male', 'Female']
    axes[1].bar(labels, prediction_result['gender_proba'])
    axes[1].set_title('Gender Probability')

    # Plot age probability
    labels = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', 'more than 70']
    axes[2].bar(labels, prediction_result['age_proba'])
    axes[2].tick_params(axis='x', rotation=45) # Rotate x-axis labels for better readability
    axes[2].set_title('Age Probability')

    # Plot ethnicity probability
    labels = ['White', 'Black', 'Latino_Hispanic', 'East Asian', 'Southeast Asian', 'Indian', 'Middle Eastern']
    axes[3].bar(labels, prediction_result['ethnicity_proba'])
    axes[3].tick_params(axis='x', rotation=45)  # Rotate x-axis labels
    axes[3].set_title('Ethnicity Probability')

    plt.tight_layout()  # Adjust layout to prevent overlapping titles
    plt.show()

def show_predictions(model, val_loader, num_images=32):
    model.eval()
    with torch.no_grad():
        for images, (gender_labels, age_labels, ethnicity_labels) in val_loader:
            images = images.to(device)
            gender_output, age_output, ethnicity_output = model(images)

            _, predicted_genders = torch.max(gender_output, 1)
            _, predicted_ages = torch.max(age_output, 1)
            _, predicted_ethnicities = torch.max(ethnicity_output, 1)

            for i in range(min(num_images, len(images))):
                # get the corresponding image from the directory
                img_path = os.path.join('fairface/FairFace', val_dataset.annotations.iloc[i, 0])
                prediction_result = predict_proba(model, img_path, transform, device)
                plot_results(prediction_result)
            break

show_predictions(model, val_loader)